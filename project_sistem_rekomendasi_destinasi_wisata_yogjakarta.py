# -*- coding: utf-8 -*-
"""Project sistem rekomendasi destinasi wisata yogjakarta.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yZsBc3JteDk1cS6R-EJ-e78ExYc0tnqV

#**Business Understanding**

Sebelum memutuskan daftar perjalanan, seseorang perlu memiliki gambaran tentang tempat-tempat tersebut.

Yogyakarta memiliki lebih dari cukup destinasi wisata, tetapi bagaimana situasi pariwisata setelah covid-19? Pada bulan Oktober 2021, sektor pariwisata di Indonesia mulai bangkit setelah jeda pandemi.

Proyek ini berisi destinasi wisata top-n di Yogyakarta berdasarkan pengguna lokal, penilaian, dan tempat.

Proyek ini bertujuan untuk mengembangkan sistem rekomendasi destinasi wisata di Yogyakarta yang memanfaatkan data pengguna dan penilaian terhadap destinasi wisata yang ada. Sistem rekomendasi ini bertujuan untuk membantu wisatawan dalam memilih tempat wisata berdasarkan ulasan pengguna sebelumnya, popularitas tempat, dan faktor-faktor lain seperti lokasi geografis, harga, serta ketersediaan fasilitas. Dengan sistem rekomendasi yang cerdas, wisatawan tidak hanya mendapatkan informasi yang sesuai dengan preferensi pribadi mereka, tetapi juga dapat mengoptimalkan pengalaman berwisata mereka dengan memilih tempat yang menawarkan nilai terbaik sesuai dengan harapan mereka.

##Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from zipfile import ZipFile
from pathlib import Path
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
sns.set_palette('Set1')
sns.set()
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import warnings
warnings.filterwarnings('ignore')
import os

"""#**Data Understanding**

Sumber data yang digunakan berasal dari dataset destinasi wisata yang dapat diakses melalui tautan berikut:

https://www.kaggle.com/code/rafkaip/sistem-rekomendasi-destinasi-wisata-kota-bandung/input

##Dataset Info

Dataset ini terdiri dari tiga file utama yaitu:
* tourism_with_id.csv - berisi informasi tentang 5 kota besar di Indonesia, untuk kasus ini, hanya Yogyakarta yang akan digunakan
* user.csv - berisi informasi pengguna untuk membuat fitur rekomendasi
* tourism_rating.csv - berisi informasi pengguna, tujuan wisata, dan penilaian untuk membuat sistem rekomendasi berdasarkan penilaian

1. tourism_with_id.csv

  File ini berisi informasi tentang destinasi wisata di Yogyakarta, dengan kolom-kolom sebagai berikut:
- Place_Id: ID unik untuk setiap destinasi wisata.
- Place_Name: Nama dari destinasi wisata.
- Description: Deskripsi destinasi wisata.
- Category: Kategori destinasi wisata.
- City: Kota destinasi wisata.
- Price: Harga tiket atau biaya masuk destinasi wisata.
- Rating: Rating keseluruhan destinasi wisata berdasarkan ulasan pengunjung.
- Coordinate: Kombinasi dari dua angka, yaitu latitude (lintang) dan longitude (bujur).
- Lat: Koordinat geografis destinasi yang menunjukkan posisi utara atau selatan dari garis khatulistiwa (lintang).
- Long: Koordinat geografis destinasi yang menunjukkan posisi timur atau barat dari garis meridian utama (bujur).

2. user.csv

  File ini berisi informasi pengguna yang memberikan ulasan terhadap destinasi wisata:
- User_Id: ID unik untuk setiap pengguna.
- Age: Umur pengguna.
- Location: Lokasi pengguna, yang menunjukkan asal kota pengguna.

3. tourism_rating.csv

  File ini berisi informasi mengenai penilaian yang diberikan oleh pengguna terhadap destinasi wisata di Yogyakarta:
- User_Id: ID pengguna yang memberikan rating.
- Place_Id: ID destinasi wisata yang diberi rating.
- Place_Ratings: Nilai rating yang diberikan oleh pengguna untuk destinasi wisata.

## Load Dataset
"""

from google.colab import drive
drive.mount('/content/drive')

rating = pd.read_csv('/content/drive/MyDrive/CODING CAMP 2025/Project Machine Learning Terapan/Project sistem rekomendasi/dataset_wisata/tourism_rating.csv')
place = pd.read_csv('/content/drive/MyDrive/CODING CAMP 2025/Project Machine Learning Terapan/Project sistem rekomendasi/dataset_wisata/tourism_with_id.csv')
user = pd.read_csv('/content/drive/MyDrive/CODING CAMP 2025/Project Machine Learning Terapan/Project sistem rekomendasi/dataset_wisata/user.csv')

"""##Eksplorasi Fitur Data"""

place.head(2)

"""Menghapus kolom Unnamed: 11 dan Unnamed: 12 karena memiliki data yang tidak terpakai"""

place = place.drop(['Unnamed: 11','Unnamed: 12'],axis=1)
place.head(2)

"""Menampilkan data kota Yogyakarta"""

# Tampilkan hanya Yogyakarta
place = place[place['City']=='Yogyakarta']
place.head()

"""Selanjutnya dilakukan pengecekkan missing value untuk memberikan gambaran lengkap tentang kualitas data dan membantu kita untuk memahami seberapa banyak data yang hilang sebelum melakukan pemrosesan lebih lanjut."""

# Fungsi untuk memeriksa nilai yang hilang untuk setiap file
def check_missing_values(df, dataset_name):
    print(f"Missing values in {dataset_name}:")
    missing_data = df.isnull().sum()
    total_missing = missing_data.sum()
    missing_percentage = (total_missing / df.size) * 100
    print(f"Total missing values: {total_missing} ({missing_percentage:.2f}%)")
    print("Missing values per column:")
    print(missing_data)
    print("\n")

# Periksa nilai yang hilang untuk setiap dataset
check_missing_values(rating, 'tourism_rating.csv')
check_missing_values(place, 'tourism_with_id.csv')
check_missing_values(user, 'user.csv')

place.loc[:, ['Time_Minutes']].mean(axis = 0)

place.info()

"""Menampilkan kolom rating untuk mengetahui variasi rating dari user"""

rating.head()

rating.info()

"""Mengubah data rating sehingga akan berisi rating tujuan di Yogyakarta untuk menyesuaikan Rating dengan Destinasi Wisata di Yogyakarta"""

# ubah data rating sehingga akan berisi rating tujuan di Yogyakarta

rating = pd.merge(rating, place[['Place_Id']], how='right', on='Place_Id')
rating.head()

rating.shape

user.head()

"""Mengubah data user menjadi user tujuan Yogyakarta untuk mencocokkan Data dengan Pengunjung yang Sesuai"""

# ubah data responden menjadi pengunjung tujuan Yogyakarta

user = pd.merge(user, rating[['User_Id']], how='right', on='User_Id').drop_duplicates().sort_values('User_Id')
user.head()

# mencari dataset responden yang memberikan penilaian untuk destinasi di Yogyakarta
user.shape

"""##Explorasi Data"""

# mengubah penamaan menjadi bahasa Inggris
place.Category[place.Category == 'Taman Hiburan'] = 'Amusement Park & Downtown Attractions'
place.Category[place.Category == 'Budaya'] = 'Culture'
place.Category[place.Category == 'Cagar Alam'] = 'National Park'
place.Category[place.Category == 'Taman Hiburan'] = 'Amusement Park'
place.Category[place.Category == 'Bahari'] = 'Marine Tourism'
place.Category[place.Category == 'Pusat Perbelanjaan'] = 'Shopping Center'

# membuat visualisasi kategori jumlah untuk destinasi Yogyakarta
sns.countplot(y='Category', data=place)
plt.title('Perbandingan Kategori Pariwisata di Yogyakarta', pad=20)
plt.show()

"""Dari hasil grafik diatas yaitu untuk memberikan gambaran mengenai distribusi jumlah tempat wisata yang terdaftar dalam berbagai kategori di Yogyakarta, membantu memahami jenis wisata yang paling banyak ada di daerah tersebut."""

# memvisualisasikan distribusi pengunjung
plt.figure(figsize=(5,3))
sns.boxplot(user['Age']);
plt.title('Distribusi Usia Pengunjung', pad=20)
plt.show()

"""Distribusi pengunjung untuk mengetahui sebaran usia dari para pengunjung yang berpartisipasi dalam survei atau yang mengunjungi tempat wisata."""

# memvisualisasikan rentang biaya masuk untuk tujuan
plt.figure(figsize=(12,6))
sns.boxplot(place['Price'])
plt.title('Distribusi Tiket Masuk untuk Destinasi Wisata Yogyakarta', pad=20)
plt.show()

"""Menunjukkan sebaran harga tiket masuk dari berbagai destinasi wisata di Yogyakarta."""

# Mengagregasi Harga dan Waktu_Detik untuk kategori tujuan
place.groupby("Category").agg({"Price":["mean", "sum"],
                       "Time_Minutes":["mean", "sum"]})

"""Dari tabel diatas ditujukan untuk mengetahui karakteristik biaya dan durasi kunjungan berdasarkan kategori tempat wisata."""

# memfilter asal kota pengunjung
askot = user['Location'].apply(lambda x : x.split(',')[0])

# memvisualisasikan asal kota pengunjung
plt.figure(figsize=(8,6))
sns.countplot(y=askot)
plt.title('Sum of Visitors Origin')
plt.show()

"""Menunjukkan distribusi asal pengunjung berdasarkan kota/kabupaten.

#**Data Preparation**

##Membuat Salinan untuk Penilaian Data
"""

# membaca dataset untuk encoding
df = rating.copy()
df.head()

"""##Encoding

Sebelum membangun model machine learning atau sistem rekomendasi, kita perlu mengubah data kategorikal (seperti `User_Id` dan `Place_Id`) menjadi format numerik.
Ini penting karena sebagian besar algoritma hanya dapat memproses data dalam bentuk angka.

Di tahap ini, kita mendefinisikan fungsi `dict_encoder()` untuk mengubah setiap nilai unik dalam kolom tertentu menjadi angka integer yang unik pula.
"""

def dict_encoder(col, data=df):

  # mengubah kolom dataframe menjadi daftar dengan nilai unik
  unique_val = data[col].unique().tolist()

  # mengenumerasi nilai kolom dari dataframe
  val_to_val_encoded = {x: i for i, x in enumerate(unique_val)}

  # proses encoding dari angka ke nilai kolom dataframe
  val_encoded_to_val = {i: x for i, x in enumerate(unique_val)}
  return val_to_val_encoded, val_encoded_to_val

"""Selanjutnya melakukan encoding terhadap kolom `User_Id`.
Tujuannya adalah untuk mengubah setiap pengguna menjadi angka unik sehingga dapat digunakan dalam proses perhitungan sistem rekomendasi atau analisis data lanjutan.
"""

# Encoding User_Id
user_to_user_encoded, user_encoded_to_user = dict_encoder('User_Id')

# Mapping User_Id ke dalam dataframe
df['user'] = df['User_Id'].map(user_to_user_encoded)

"""Setelah encoding pengguna, kita lanjutkan dengan mengubah data `Place_Id` menjadi angka.
Langkah ini akan membantu dalam proses analisis interaksi pengguna dengan tempat wisata.
"""

# Encoding Place_Id
place_to_place_encoded, place_encoded_to_place = dict_encoder('Place_Id')

# Mapping Place_Id ke dalam dataframe place
df['place'] = df['Place_Id'].map(place_to_place_encoded)

"""##Melihat Gambaran Umum Modelling Data

Sebelum membangun model, penting untuk memahami skala dan karakteristik data yang tersedia. Pada tahap ini, kita akan menghitung jumlah pengguna (`User`) dan jumlah tempat (`Place`) yang telah melalui proses encoding.

Kemudian, kita juga memastikan bahwa data pada kolom `Place_Ratings` berada dalam format numerik (`float32`) agar bisa diproses oleh algoritma machine learning. Informasi mengenai nilai **minimum** dan **maksimum rating** juga ditampilkan untuk memahami rentang penilaian yang diberikan pengguna terhadap tempat wisata.

Langkah ini sangat berguna sebagai gambaran awal sebelum masuk ke tahap pelatihan model.
"""

# mendapatkan panjang user & user
num_users, num_place = len(user_to_user_encoded), len(place_to_place_encoded)

# mengubah rating menjadi float
df['Place_Ratings'] = df['Place_Ratings'].values.astype(np.float32)

# mendapatkan rating minimum dan maksimum
min_rating, max_rating = min(df['Place_Ratings']), max(df['Place_Ratings'])

print(f'Number of User: {num_users}, Number of Place: {num_place}, Min Rating: {min_rating}, Max Rating: {max_rating}')

# mengacak dataset
df = df.sample(frac=1, random_state=42)
df.head(2)

"""#**Modelling**

##Mengalokasikan data train dan test

Dilakukan pembagian data untuk menyiapkan data input (`x`) dan target (`y`) yang akan digunakan dalam proses pelatihan model sistem rekomendasi.
"""

# membuat variabel x untuk mencocokkan user menjadi satu nilai
x = df[['user', 'place']].values

# membuat variabel y untuk memulai rating
y = df['Place_Ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# mengalokasikan data training 80% & data validation 20%
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

"""##Model Preparation

Pada tahap ini, kita membangun sebuah model rekomendasi berbasis *neural collaborative filtering* menggunakan TensorFlow Keras API. Model ini dinamakan `RecommenderNet` dan dibuat sebagai subclass dari `tf.keras.Model`. Model ini dilatih untuk mempelajari representasi laten dari pengguna dan tempat, sehingga dapat memprediksi seberapa besar kemungkinan seorang pengguna menyukai suatu tempat berdasarkan interaksi sebelumnya.
"""

class RecommenderNet(tf.keras.Model):

  # Function initialization
  def __init__(self, num_users, num_places, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_places = num_places
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.places_embedding = layers.Embedding( # layer embeddings places
        num_places,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.places_bias = layers.Embedding(num_places, 1) # layer embedding places bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # layer embedding 2
    places_vector = self.places_embedding(inputs[:, 1]) # layer embedding 3
    places_bias = self.places_bias(inputs[:, 1]) # layer embedding 4

    dot_user_places = tf.tensordot(user_vector, places_vector, 2)

    x = dot_user_places + user_bias + places_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""Setelah arsitektur `RecommenderNet` didefinisikan, langkah berikutnya adalah mengkompilasi dan melatih model tersebut."""

model = RecommenderNet(num_users, num_place, 50) # model initialization

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.0004),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Selanjutnya digunakan fungsi Callback dibuat untuk menghentikan pelatihan lebih awal jika nilai RMSE pada data validasi telah mencapai target tertentu (kurang dari 0.25). Hal ini bertujuan untuk:
- Menghindari overfitting,
- Menghemat waktu pelatihan.
"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_root_mean_squared_error')<0.25):
      print('Fulfilled expected validation matrix')
      self.model.stop_training = True

"""Lalu, Model dilatih selama maksimum 100 *epoch* menggunakan data training, dan divalidasi dengan data validation (20% dari data). Selama proses ini, performa model dipantau melalui metrik RMSE. Pelatihan ini bertujuan agar model dapat memahami pola interaksi antara pengguna dan tempat berdasarkan histori rating."""

# training

history = model.fit(
    x = x_train,
    y = y_train,
    epochs = 100,
    validation_data = (x_val, y_val),
    callbacks = [myCallback()]
)

"""#Evaluation Model"""

# Ambil data dari objek history
history_df = pd.DataFrame(history.history)

# Tambahkan kolom epoch
history_df['Epoch'] = history_df.index + 1

# Ubah nama kolom agar sesuai format yang diinginkan
formatted_df = history_df.rename(columns={
    'root_mean_squared_error': 'Train RMSE',
    'val_root_mean_squared_error': 'Validation RMSE',
    'loss': 'Train Loss',
    'val_loss': 'Validation Loss'
})

# Urutkan kolom sesuai permintaan
formatted_df = formatted_df[[
    'Epoch',
    'Train RMSE',
    'Validation RMSE',
    'Train Loss',
    'Validation Loss'
]]

# Tampilkan tabel
print("Hasil Evaluasi Model:\n")
print(formatted_df.to_string(index=False))

"""Tabel hasil evaluasi model diatas menampilkan informasi tentang RMSE dan Loss untuk pelatihan serta validasi pada setiap epoch akan muncul. Ini memberi gambaran jelas mengenai performa model dari awal hingga akhir pelatihan."""

# menunjukkan plot loss and validation
plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.ylim(ymin=0, ymax=0.4)
plt.legend(['train', 'test'], loc='center left')
plt.show()

"""Plot yang dihasilkan menunjukkan dua garis, satu untuk root_mean_squared_error pada data pelatihan dan satu untuk val_root_mean_squared_error pada data validasi, sehingga kita bisa memantau performa model pada kedua set data tersebut sepanjang epoch.

#Prediksi 7 Destinasi yang direkomendasikan

##Persiapan DataFrame untuk Menampilkan Rekomendasi

Pada langkah ini, kita menyiapkan DataFrame untuk menyusun informasi yang akan digunakan dalam sistem rekomendasi. Data ini mencakup tempat-tempat yang ada, dengan informasi seperti nama tempat, kategori, rating, dan harga. Selain itu, kita juga mengambil data rating dari pengguna untuk menentukan destinasi yang relevan berdasarkan interaksi pengguna.
"""

place_df = place[['Place_Id','Place_Name','Category','Rating','Price']]
place_df.columns = ['id','place_name','category','rating','price']
df = rating.copy()

"""##Contoh user untuk Menampilkan Rekomendasi

Langkah berikutnya adalah memilih seorang pengguna secara acak, mengambil daftar tempat yang telah dikunjungi pengguna tersebut, dan menentukan tempat-tempat lain yang belum dikunjungi oleh pengguna tersebut untuk digunakan dalam rekomendasi.
"""

# user sampling
user_id = df.User_Id.sample(1).iloc[0]
place_visited_by_user = df[df.User_Id == user_id]

# data location yang belum dikunjungi
place_not_visited = place_df[~place_df['id'].isin(place_visited_by_user.Place_Id.values)]['id']
place_not_visited = list(
    set(place_not_visited)
    .intersection(set(place_to_place_encoded.keys()))
)

place_not_visited = [[place_to_place_encoded.get(x)] for x in place_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_place_array = np.hstack(
    ([[user_encoder]] * len(place_not_visited), place_not_visited)
)

"""##Menampilkan Rekomendasi untuk user

Menampilkan rekomendasi tempat berdasarkan rating yang diprediksi oleh model. Sistem ini akan memberikan daftar 7 tempat teratas yang direkomendasikan untuk pengguna yang sebelumnya dipilih, berdasarkan tempat-tempat yang belum mereka kunjungi.
"""

# top 7 Rekomendasi
ratings = model.predict(user_place_array).flatten()
top_ratings_indices = ratings.argsort()[-7:][::-1]
recommended_place_ids = [
    place_encoded_to_place.get(place_not_visited[x][0]) for x in top_ratings_indices
]

print('Daftar rekomendasi untuk: {}'.format('User ' + str(user_id)))
print('===' * 15,'\n')
print('----' * 15)
print('Tempat dengan rating tertinggi dari user')
print('----' * 15)

top_place_user = (
    place_visited_by_user.sort_values(
        by = 'Place_Ratings',
        ascending=False
    )
    .head(5)
    .Place_Id.values
)

place_df_rows = place_df[place_df['id'].isin(top_place_user)]
for row in place_df_rows.itertuples():
    print(row.place_name, ':', row.category)

print('')
print('----' * 15)
print('Top 7 rekomendasi tempat')
print('----' * 15)

recommended_place = place_df[place_df['id'].isin(recommended_place_ids)]
for row, i in zip(recommended_place.itertuples(), range(1,8)):
    print(i,'.', row.place_name, '\n    ', row.category, ',', 'Entrance Fee', row.price, ',', 'Rating', row.rating,'\n')

print('==='*15)

"""Insight:

- Berdasarkan tempat yang sudah dikunjungi, user 213 memiliki minat yang kuat terhadap Marine Tourism (Wisata Laut), yang tercermin dalam beberapa rekomendasi tempat seperti Pantai Nguluran, Pantai Wediombo, dan Pantai Ngrenehan.
- Selain itu, ada juga rekomendasi yang berkaitan dengan National Park, seperti Taman Sungai Mudal, yang bisa memberikan variasi dalam pengalaman wisata alam pengguna.
- Semua tempat yang direkomendasikan memiliki rating yang cukup tinggi (di atas 4), menunjukkan bahwa destinasi-destinasi ini cukup populer dan disukai oleh pengunjung lain.
"""
